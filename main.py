from fastapi import FastAPI, Request, Form
from fastapi.responses import Response
from twilio.twiml.voice_response import VoiceResponse, Gather
from openai import OpenAI
from dotenv import load_dotenv
import os
import requests


load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1"
)

app = FastAPI()

@app.get("/call")
@app.head("/call")
async def verify_call():
    return Response(content="OK", media_type="text/plain")

@app.post("/call")
async def handle_call(
    request: Request,
    SpeechResult: str = Form(default=""),
    From: str = Form(default=""),
    CallSid: str = Form(default="")
):
    response = VoiceResponse()

    if SpeechResult:
        print(f"ğŸ”” Ù…ÙƒØ§Ù„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù†: {From} | Call SID: {CallSid}")
        print(f"ğŸ™ï¸ SpeechResult = {SpeechResult}")
        try:
            gpt_reply = ask_gpt(SpeechResult)
            print(f"ğŸ¤– Ø±Ø¯ GPT: {gpt_reply}")
            response.say(gpt_reply, language="ar-SA")
        except Exception as e:
            print(f"âŒ GPT Error: {e}")
            response.say("Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. Ø­Ø§ÙˆÙ„ Ù„Ø§Ø­Ù‚Ù‹Ø§.", language="ar-SA")
    else:
        gather = Gather(input="speech", action="/call", method="POST", language="ar-SA", timeout=5)
        gather.say("Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒØŒ Ø£Ø®Ø¨Ø±Ù†ÙŠ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ", language="ar-SA")
        response.append(gather)
        response.say("Ù„Ù… Ø£Ø³Ù…Ø¹ Ø£ÙŠ Ø´ÙŠØ¡ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹.", language="ar-SA")

    return Response(content=str(response), media_type="application/xml")

def ask_gpt(prompt):
    response = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers={
            "Authorization": f"Bearer {os.getenv('OPENROUTER_API_KEY')}",
            "Content-Type": "application/json"
        },
        json={
            "model": "mistralai/mistral-7b-instruct",
            "messages": [
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØµÙˆØªÙŠ Ø°ÙƒÙŠ. ØªØ­Ø¯Ø« Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰."},
                {"role": "user", "content": prompt}
            ]
        }
    )
    response_json = response.json()
    return response_json["choices"][0]["message"]["content"].strip()


#    chat_completion = client.chat.completions.create(
#        "model": "mistralai/mistral-7b-instruct",
#        messages=[
#            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØµÙˆØªÙŠ Ø°ÙƒÙŠ Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡."},
#            {"role": "user", "content": prompt}
#        ]
#    )
#    return chat_completion.choices[0].message.content.strip()
